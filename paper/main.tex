\documentclass{article}
\usepackage{arxiv}

\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}

% \usepackage[
% backend=biber,
% style=alphabetic,
% sorting=ynt
% ]{biblatex}



\title{GraphSASRec: модель последовательных рекомендаций на основе самовнивания, дополненная графовыми представлениями.}

\author{ 
	\textbf{Матвеев Артем} \\
    Московский государственный университет \\ 
	имени М. В. Ломоносова \\
	\texttt{matfu21@ya.ru} \\
	\And
	\textbf{Майсурадзе Арчил Ивериевич} \\
    Московский государственный университет \\
	имени М. В. Ломоносова \\
	\texttt{artchil@mail.ru} \\
}
\date{2023}

\renewcommand{\shorttitle}{}

\begin{document}
\maketitle

\begin{abstract}
	% \lipsum[1]
	Последовательные модели, решающие задачу предсказания следующего взаимодействия пользователя на 
	основе кодирования его исторических событий, являются популярным решением для построение 
	персонализированных рекомендательных систем как в индустрии, так и в академии. Преимуществами 
	таких моделей являются: учет порядка, в котором следуют исторические события и оценка долгосрочных 
	интересов пользователя. Однако подобные подходы недостаточно эксплуатируют полезный коллаборативный
	сигнал и плохо представляют объекты из длинного хвоста. Популярным решением этих проблем являются 
	методы, основанные на применении графовых нейронных сетей к двудольному графу взаимодействий 
	пользователей. В работе предлагается с другой стороны взглянуть на модель последовательных рекомендаций
	как на графовую сеть со стороны пользователя. Предлагается метод увеличения глубины этой сети,
	сохраняющий длину истории пользователя при минимальных накладных расходах. Предлагается аналог logQ 
	корректировки для задачи link-prediction. Наблюдаемые результаты демонстрируют улучшение с 
	точки зрения метрик ранжирования и разнообразия выдачи.
\end{abstract}


\keywords{Информационный поиск \and Последовательные рекомендации \and Графовые нейронные сети}

\section{Введение}

Последовательные рекомендательные системы - это класс рекомендательных систем, которые принимают 
во внимание порядок взаимодействий пользователя и пытаются предсказать следующее его взаимодейсвие.
Учет порядка является важной состоявляющей во многих рекомендательных сценариях: если пользователь
только что купил мобильный телефон, то следующая покупка с большой долей вероятности будет 
аксессуаром к нему. Ранее такая задача решалась с помощью подходов, основанных на Марковских 
цепях \cite{mc} или рекуррентных нейронных сетях \cite{rnn1,rnn2,rnn3}. Но после появления архитектуры
трансформер \cite{transformer} и его успеха в задачах распознования естественного языка, наиболее успешными
стали модели, основанные на обработке последовательностей действий пользователя с помощью трансформера 
\cite{sasrec,bert4rec,gsasrec}. 

Другим популярным подходом в рекомендательных системах являются графовые нейронные 
сети \cite{lightgcn,lightgcl,hetergcl,herograph,slgcn}. В этом подходе информация, которая есть в рекомендательной 
системе, рассматривается в виде графов. Большинство данных в любой рекомендательной системе по
существу имееют графовую структуру. Например, данные взаимодействий в рекомендательном сервисе могут быть
представлены в виде двудольного графа, вершины одной доли которого - пользователи, другой объекты (например, товары), а
наблюдаемый взаимодействия - ребра. Пусть нам дан такой граф. Ключевая идея графовых нейронный сетей заключается в
итеративной агрегации признаковых представлений соседей в графе и объединение этой агрегированной информации
с представлением вершины, для которой рассматривается соседство \cite{survey1}. Такая операция называется распространением
сообщений \cite{lightgcn,sage}. Формально ее можно записать в следующем виде:$$
Aggregation: n^{(l)}_v = Aggregator_l(\{h^l_u, \forall u \in \mathcal{N}_v\}),$$$$Update: h^{(l + 1)}_v = Updater_l(h_v^{(l)}, n_v^{(l)}),
$$ где $h_u^{(l)}$ определяется как представление вершины $u$ после $l$-ого слоя графовой сети. $Aggregator_l$ и $Update_l$
представляют собой обучаемые функции агрегации соседей и обновления представления вершины на $l$-ом слое. В качестве функции 
агрегации могут выступать как простые варианты по типу max-pooling, mean-pooling \cite{sage}, так и более сложные, например: 
importance-pooling \cite{pinsage}, агрегация на основе контекста \cite{multisage}, механизм внимания \cite{gat}, агрегация
на базе трансформера \cite{multibisage}. В качестве функции обновления могут выступать как простые архитектуры на базе несколькоих
полносвязных слоев \cite{sage, pinsage}, так и более сложные на базе трансформера \cite{multibisage}.

Успех графовых подходов в рекомендательных системах можно объяснить тремя причинами \cite{survey2}. Во-первых,
выражая все данные в виде вершин и ребер графа, графовые нейронные сети предоставляют общий способ
использовать все имеющиеся данные \cite{twhin}, тогда как традиционные рекомендательные системы чаще
всего фокусируются на одном или небольшом количестве источников данных. Во-вторых, подобные модели могут явно
утилизировать связи высокого порядка (товар $X$ купил пользователь $U$, которому понравился товар $Y$, который в свою очередь
похож на товар $Z$). В классических моделях этот учет происходит только неявно. Причем многие работы показывают, что от увеличения
глубины графовой сети (то есть явного учета взаимодействий более высокого порядка) наблюдается рост целевых 
метрик \cite{lightgcn,sage,podcastgnn}. В-третьих, целевой сигнал в рекомендательных системах очень 
разреженный (например, покупка). Графовые подходы позволяют использовать методы, основанные на обучении с частичным 
привлечением учителя \cite{semisupervised}, что приводит к улучшению качества моделей.

При внимательном взгляде на модели последовательных рекомендаций, можно увидеть в них графовую нейронную
сеть со стороны пользователя. Как было упомянуто выше, графовые нейронные сети выучивают лучшее 
семантическое пространство, если начинать использовать в модели связи все большего порядка. Однако, на практике,
длина последовательности пользователя варьируется от сотен \cite{sasrec,yandex}, до тысяч \cite{pinnerformer,transact}
исторических событий. В этом случае, при построении соседств следующих уровней, возникает проблема
экспоненциального роста их размера \cite{sage}, что приводит к невозможности применения графовых методов 
в классическом виде.

Основной вклад заключается в следующем:

\begin{enumerate}
	\item[\textbullet] Предлагается с другой стороны взглянуть на задачу последовательных рекомендаций. Найти в ней сходства с подходами, связанными с графовыми
нейронными сетями, и использовать методы из этой области для улучшения моделей последовательных рекомендаций.
	\item[\textbullet] Предлагается метод увеличения глубины связей, утилизируемых в моделях последовательных рекомендаций, на оснвое 
предобученных графовых представлений. При этом сохраняющей длину истории пользователя при минимальных накладных расходах.
	\item[\textbullet] Представляется способ корректироваки, получающий асимптотически несмещенную оценку градиента для функции потерть в задаче link-prediction. 
Приводятся результаты, демонстрирующие улучшения с точки зрения метрик полноты по сравнению с решением, не использующим эту корректировку.
	\item[\textbullet] Представляется модифицированная архитектура модели последовательных рекомендаций, учитывающая связи более высоких порядков. Демонстрируются
результаты, показывающие, что такой подходи приводит к росту метрик ранжирования. 
\end{enumerate}
 

\section{Постановка задачи}

\subsection{Последовательные рекомендации}
В последовательных рекомендациях рассматривается задача предсказания следующего положительного взаимодействия 
пользователя по последовательности его исторических действий $S^u = (S_1^u, S_2^u, \dots, S_{|S^u|}^u)$.
Во время обучения, на момент времени $t$, модель предсказывает следующий объект интереса пользователя на основе его
взаимодействий, произошедших раньше момента $t$. На вход модели поступает последоватлеьность
$(S_1^u, S_2^u, \dots, S^u_{|S^u| - 1})$. Ожидаемый выход модели - следующее положительное взаимодействия $S^u_{|S^u|}$. 
В данной работе рассматривается модель SASRec \citep{sasrec}, в основе которой лежит декодер блок трансформера \cite{transformer},
на выходе которого тоже последовательность. 
Поэтому задачу можно переформулировать в эквивалентном виде, как задачу предсказания сдвинутой версии 
последовательности $(S_2^u, S_3^u, \dots, S^u_{|S^u|})$.

\subsection{Предсказание ребра}

Дан граф $G = (V, E, X)$, где $V$ - множество вершин, $E$ - множество ребер, $X \in \mathbb{R}^{|V| \times d}$
- $d$-размерные векторные представления входных вершин. Задача предсказания ребра формулируется как задача
определения существования (или появления в будущем, если граф рассматривается как динамический \cite{dyngnn}) ребра $e_{ij}$
между вершинами $i$ и $j$, где $i, j \in V$, и $e_{ij} \not \in E$.

\section{Сопутствующие работы}

\subsection{Последовательные рекомендации в индустрии}

\subsection{Транcдуктивные графовые модели}

\subsection{Индуктивные графовые модели}

\section{Метод}

\section{Эксперименты}

\section{Заключение}

\bibliographystyle{abbrv}
\bibliography{references}

\end{document}